{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reducing the size of Word2vec model\n",
    "\n",
    "inspired by and English word data taken from : https://github.com/eyaler/word2vec-slim\n",
    "\n",
    "download the word list files to `dicts` dir from https://github.com/eyaler/word2vec-slim/tree/master/source/dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import time\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words2.txt.gz: 235886 -> 234371\n",
      "urban50.txt.gz: 86724 -> 86724\n",
      "words.txt.gz: 354986 -> 354984\n",
      "words3.txt.gz: 479829 -> 462984\n",
      "topic_list_slim-model_26396topics_topn10_dep5_thr0.5.txt.gz: 26396 -> 26396\n",
      "combined: 546117\n"
     ]
    }
   ],
   "source": [
    "# laod word directories (english words + our topic words)\n",
    "\n",
    "words = set()\n",
    "for dict_filename in os.listdir('dicts'):\n",
    "    with gzip.open('dicts/'+dict_filename, 'rt', encoding='utf8') as f:\n",
    "        temp = f.readlines()\n",
    "        save_len = len(temp)\n",
    "        for i in range(len(temp)):\n",
    "            temp[i] = temp[i].strip().lower()\n",
    "        temp = set(temp)\n",
    "        print('%s: %d -> %d' % (dict_filename, save_len, len(temp)))\n",
    "    words |= temp\n",
    "print('combined: %d' % (len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading original model 0.79 min\n"
     ]
    }
   ],
   "source": [
    "# load the big model \n",
    "\n",
    "start = time.time()\n",
    "model = KeyedVectors.load_word2vec_format('/home/dzon/kajo/jiri_w2v', binary=True)\n",
    "print('Finished loading original model %.2f min' % ((time.time()-start)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3936720192"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much memory the model occupies (~4GB)\n",
    "\n",
    "from pympler import asizeof\n",
    "asizeof.asizeof(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec total words: 2556470\n",
      "non-phrases: 1355029\n",
      "phrases: 1201441\n"
     ]
    }
   ],
   "source": [
    "print('word2vec total words: %d' % len(model.vocab))\n",
    "print('non-phrases: %d' % len([w for w in model.vocab.keys() if '_' not in w]))\n",
    "print('phrases: %d' % len([w for w in model.vocab.keys() if '_' in w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzon/env/lib/python3.6/site-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slim: 196944\n",
      "suffix grace words: 22349\n"
     ]
    }
   ],
   "source": [
    "max_suffix_len = 2\n",
    "min_base_len = 8\n",
    "\n",
    "indices_to_delete = []\n",
    "j = 0\n",
    "suffix_grace_words = 0\n",
    "for i,w in enumerate(model.index2word):\n",
    "    l = w.strip().lower()\n",
    "    found = False\n",
    "    if l in words:\n",
    "        found = True\n",
    "    else:\n",
    "        for s in range(1, 1+max_suffix_len):\n",
    "            if len(l)-s<min_base_len:\n",
    "                break\n",
    "            elif l[:-s] in words:\n",
    "                suffix_grace_words += 1\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "    if found:\n",
    "        model.vocab[w].index = j\n",
    "        j += 1\n",
    "    else:\n",
    "        del model.vocab[w]\n",
    "        indices_to_delete.append(i)\n",
    "\n",
    "model.syn0 = np.delete(model.syn0, indices_to_delete, axis=0)\n",
    "print('slim: %d' % len(model.vocab))\n",
    "print('suffix grace words: %d' % (suffix_grace_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_model_name = 'w2v-jiri-slim.bin'\n",
    "model.save_word2vec_format(slim_model_name, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading slim model 3.4 sec\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "\n",
    "start = time.time()\n",
    "model = KeyedVectors.load_word2vec_format(slim_model_name, binary=True)\n",
    "print('Finished loading slim model %.1f sec' % ((time.time()-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306357792"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how much memory the model occupies (~300MB)\n",
    "\n",
    "from pympler import asizeof\n",
    "asizeof.asizeof(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'disproportionable',\n",
       " 'psychophobia',\n",
       " 'rowlandite',\n",
       " 'unmedalled',\n",
       " 'godmaker',\n",
       " 'snottie',\n",
       " 'unagricultural',\n",
       " 'usitative',\n",
       " \"bachelor's-buttons\",\n",
       " 'specialised/minority',\n",
       " 'puppetlike',\n",
       " 'resp.',\n",
       " 'strap-on',\n",
       " 'sing-song',\n",
       " 'pre-employment',\n",
       " 'contradictedness',\n",
       " 'nonvagrantly',\n",
       " 'macbitch',\n",
       " 'cubonavicular']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlist = list(words)\n",
    "wlist[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
