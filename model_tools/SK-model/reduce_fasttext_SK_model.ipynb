{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering the words in Fasttext SK model\n",
    "* we leave only words which exist in Slovak dictionaries\n",
    "* 3 lists of SK words are taken with total ~2mil words\n",
    "* final model has 1043624 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'abakus',\n",
       " 'abakuse',\n",
       " 'abakusmi',\n",
       " 'abakusoch',\n",
       " 'abakusom',\n",
       " 'abakusov',\n",
       " 'abakusu',\n",
       " 'abakusy',\n",
       " 'abatiša',\n",
       " 'abatišami',\n",
       " 'abatiše',\n",
       " 'abatiši',\n",
       " 'abatišiach',\n",
       " 'abatišiam',\n",
       " 'abatišou',\n",
       " 'abatišu',\n",
       " 'abatíš']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# morphology database from https://korpus.sk/morphology_database.html\n",
    "import re\n",
    "\n",
    "words = set()\n",
    "\n",
    "with open('/home/dzon/kajo/spacy_multilang/ma-2015-02-05.txt', 'rt', encoding='utf8') as f:\n",
    "    temp = f.readlines()\n",
    "    for line in temp:\n",
    "        line = line.strip()\n",
    "        lemma,word,tag = line.split(\"\\t\")\n",
    "        word = re.sub(\"\\W\",\"\", word)\n",
    "        words.add(word.strip().lower())\n",
    "        \n",
    "\n",
    "print(len(words))\n",
    "sorted(list(words))[:20]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'a', 'aba', 'abak', 'abaka', 'abakteriálna', 'abakteriálne', 'abakteriálneho', 'abakteriálnej', 'abakteriálnejšej', 'abakteriálnejšia', 'abakteriálnejšie', 'abakteriálnejšieho', 'abakteriálnejšiemu', 'abakteriálnejšiu', 'abakteriálnejšom', 'abakteriálnejšou', 'abakteriálnejší', 'abakteriálnejších', 'abakteriálnejším']\n",
      "1021980\n",
      "combined: 1498877\n"
     ]
    }
   ],
   "source": [
    "# http://www.sk-spell.sk.cx/slovak-wordlist\n",
    "\n",
    "with open('/home/dzon/kajo/translations/sk_wordlist.txt', 'rt', encoding='utf8') as f:\n",
    "    temp = f.readlines()\n",
    "    save_len = len(temp)\n",
    "    for i in range(len(temp)):\n",
    "        temp[i] = temp[i].strip().lower()\n",
    "        temp[i] = re.sub(\"\\W\",\"\", temp[i])\n",
    "    print(sorted(list(temp))[:20])\n",
    "    temp = set(temp)\n",
    "    print(len(temp))\n",
    "words |= temp\n",
    "print('combined: %d' % (len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sk_words_skoro_max.txt', 'w') as f:\n",
    "    for item in sorted(list(words)):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'a', 'aa', 'aaa', 'aaaa', 'aaaaa', 'aaaaaa', 'aaaaaaa', 'aaaaaaaa', 'aaaaaaaaaa', 'aaaaaaaaaaa', 'aaaaaaaaaaaaaaaaaaaaa', 'aaaaaaaaaaaaaaaah', 'aaaaaaah', 'aaaaaaahh', 'aaaaaaahhhhhhh', 'aaaaaah', 'aaaaah', 'aaaaahhh', 'aaaaahhhhh']\n",
      "1657175\n",
      "combined: 2069285\n"
     ]
    }
   ],
   "source": [
    "# http://p.brm.sk/sk_wordlist/\n",
    "\n",
    "temp_words = set()\n",
    "\n",
    "with open('/home/dzon/kajo/spacy_multilang/sk.txt', 'rt', encoding='utf8') as f:\n",
    "    temp = f.readlines()\n",
    "    for line in temp:\n",
    "        line = line.strip()\n",
    "        #print(line)\n",
    "        tmp = line.split(\" \")\n",
    "        #print(\"-\",word,\"-\")\n",
    "        word = re.sub(\"\\W\",\"\", tmp[0])\n",
    "        temp_words.add(word.strip().lower())\n",
    "print(sorted(list(temp_words))[:20]  )\n",
    "print(len(temp_words))\n",
    "words_max = words\n",
    "words_max |= temp_words\n",
    "print('combined: %d' % (len(words_max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sk_words_max.txt', 'w') as f:\n",
    "    for item in sorted(list(words_max)):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import time\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading original model 0.82 min\n"
     ]
    }
   ],
   "source": [
    "# load the big model \n",
    "start = time.time()\n",
    "model = KeyedVectors.load_word2vec_format('/mnt/data/data/models-fasttext/cc.sk.300.vec.bin', binary=True)\n",
    "print('Finished loading original model %.2f min' % ((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec total words: 2000000\n",
      "non-phrases: 1999999\n",
      "phrases: 1\n"
     ]
    }
   ],
   "source": [
    "print('word2vec total words: %d' % len(model.vocab))\n",
    "print('non-phrases: %d' % len([w for w in model.vocab.keys() if '_' not in w]))\n",
    "print('phrases: %d' % len([w for w in model.vocab.keys() if '_' in w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dzon/env/lib/python3.6/site-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slim: 1043624\n",
      "suffix grace words: 0\n"
     ]
    }
   ],
   "source": [
    "max_suffix_len = 2\n",
    "min_base_len = 8\n",
    "\n",
    "indices_to_delete = []\n",
    "j = 0\n",
    "suffix_grace_words = 0\n",
    "for i,w in enumerate(model.index2word):\n",
    "    l = w.strip().lower()\n",
    "    found = False\n",
    "    if l in words:\n",
    "        found = True\n",
    "    if found:\n",
    "        model.vocab[w].index = j\n",
    "        j += 1\n",
    "    else:\n",
    "        del model.vocab[w]\n",
    "        indices_to_delete.append(i)\n",
    "\n",
    "model.syn0 = np.delete(model.syn0, indices_to_delete, axis=0)\n",
    "print('slim: %d' % len(model.vocab))\n",
    "print('suffix grace words: %d' % (suffix_grace_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_model_name = '/mnt/data/data/models-fasttext/cc.sk.300-slim.vec.bin'\n",
    "model.save_word2vec_format(slim_model_name, binary=True)\n",
    "slim_model_name = '/mnt/data/data/models-fasttext/cc.sk.300-slim.vec'\n",
    "model.save_word2vec_format(slim_model_name, binary=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
